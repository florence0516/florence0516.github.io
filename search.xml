<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>命名实体识别（NER）调研</title>
    <url>/2020/11/27/NER/</url>
    <content><![CDATA[<p>本文介绍了现有的一些关于命名实体识别技术的研究方法，命名实体识别技术是信息抽取技术的一部分，是很多任务的基础工作。</p>
<a id="more"></a>

<h3 id="命名实体识别技术调研"><a href="#命名实体识别技术调研" class="headerlink" title="命名实体识别技术调研"></a>命名实体识别技术调研</h3><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>命名实体就是命名实体识别的研究主体，一般包括三大类（实体类、时间类和数字类）和七小类（人名、地名、机构名、时间、日期、货币和百分比）命名实体。</p>
<p>命名实体识别（Named Entity Recognition，NER）又称专名识别，从早期基于字典和规则的方法，到传统机器学习的方法，再到近年来基于深度学习的各类方法，其研究进展的大概趋势如下图所示。</p>
<img src="/2020/11/27/NER/p1.png" alt="NER发展趋势" style="zoom:80%;">

<h4 id="基于字典和规则的方法"><a href="#基于字典和规则的方法" class="headerlink" title="基于字典和规则的方法"></a>基于字典和规则的方法</h4><p>基于字典和规则的方法是命名实体识别任务中最古老的方法。利用手工编写的规则，提取特征，比如关键词、指示词、位置词等，收集特征词，并且给每一个规则都赋予一个权值，当规则冲突的时候，选择权值最高的规则进行命名实体类型的判别；但是这些规则往往依赖于具体语言、领域和文本风格，编制过程耗时且难以涵盖所有的语言现象，特别容易产生错误，系统可移植性不好，对于不同的系统需要语言学专家重新书写规则。</p>
<h4 id="基于传统机器学习的方法"><a href="#基于传统机器学习的方法" class="headerlink" title="基于传统机器学习的方法"></a>基于传统机器学习的方法</h4><p>基于传统机器学习的方法主要包括隐马尔可夫模型（Hidden Markov Model，HMM）、支持向量机（support vector machines，SVM）、条件随机场[1]（Conditional Random Fields，CRF）等。在此类方法中，NER被当作序列标注问题，利用大规模语料来学习出标注模型，从而对句子的各个位置进行标注。隐马尔可夫模型（HMM）认为观测到的句子中的每个词都是相互独立的，而且当前时刻的标注只与前一时刻的标注相关，但实际上，句子中的每个词是存在依赖关系的，且当前时刻的标注应该与前一时刻以及后一时刻的标注都相关联，因此，HMM模型虽然在训练以及识别时的效率更高，但是准确率比较低，效果不够理想；条件随机场（CRF）为命名实体识别提供了一个特征灵活、全局最优的标注框架，能对隐含状态建模，学习状态序列的特点，在标注准确率上有一定优势，但是收敛速度较慢、所需的训练时间也更长。基于统计机器学习的方法中，CRF是使用最广泛的，它的目标函数不仅考虑输入的状态特征函数，而且还包含了标签转移特征函数。在训练时可以使用随机梯度下降法（Stochastic Gradient Descent，SGD）学习模型参数。在已知模型时，给输入序列求预测输出序列即求使目标函数最大化的最优序列，是一个动态规划问题，可以使用Viterbi算法解码来得到最优标签序列。</p>
<h4 id="基于深度学习的方法"><a href="#基于深度学习的方法" class="headerlink" title="基于深度学习的方法"></a>基于深度学习的方法</h4><p>随着硬件计算能力的发展以及词的分布式表示（word embedding）的提出，神经网络可以有效处理这种序列标注任务：将分词从离散的独热向量（one-hot）表示映射到低维空间中成为稠密的词向量（embedding），随后将句子的embedding序列输入到卷积神经网络（Convolutional Neural Networks，CNN）或循环神经网络（Recurrent Neural Network，RNN）中，用神经网络自动提取特征，归一化指数（Softmax）函数来预测每个分词的标签。这种方法使得模型的训练成为一个端到端的过程，不依赖于特征工程，是一种数据驱动的方法，但网络种类繁多、对参数设置依赖大，模型可解释性差。此外，这种方法的一个缺点是对每个分词打标签的过程是独立的进行，不能直接利用上文已经预测的标签，进而导致预测出的标签序列可能是无效的。因此，学界提出了深度学习模型（DL）+CRF的混合模型做序列标注，在神经网络的输出层接入CRF层来做句子级别的标签预测，使得标注过程不再是对各个分词的独立分类。</p>
<h4 id="近期工作"><a href="#近期工作" class="headerlink" title="近期工作"></a>近期工作</h4><p>近年来，在基于神经网络结构的NER研究主要集中在三个方面：一是，使用流行的注意力机制[2]（Attention Mechanism）来提高模型效果；二是，针对少量标注训练数据或无标注数据进行的一些研究，其中包括了迁移学习[3]和半监督学习[4]，这也是未来研究的重点。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1].  Lafferty J, McCallum A, Pereira F C N. Conditional random fields: Probabilistic models for segmenting and labeling sequence data[J]. 2001.</p>
<p>[2].  Zukov-Gregoric A, Bachrach Y, Minkovsky P, et al. Neural named entity recognition using a self-attention mechanism[C]. 2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI). IEEE, 2017: 652-656.</p>
<p>[3].  Beryozkin G, Drori Y, Gilon O, et al. A Joint Named-Entity Recognizer for Heterogeneous Tag-sets Using a Tag Hierarchy[J]. arXiv preprint arXiv:1905.09135, 2019.</p>
<p>[4].  Peters M E, Ammar W, Bhagavatula C, et al. Semi-supervised sequence tagging with bidirectional language models[J]. arXiv preprint arXiv:1705.00108, 2017.</p>
]]></content>
      <tags>
        <tag>调研报告</tag>
      </tags>
  </entry>
  <entry>
    <title>短文本相似度计算调研</title>
    <url>/2020/11/27/%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6/</url>
    <content><![CDATA[<p>本文是对短文本相似度计算任务的调研报告，简单介绍了目前解决该问题的一些方法。</p>
<a id="more"></a>

<h3 id="短文本相似度计算调研"><a href="#短文本相似度计算调研" class="headerlink" title="短文本相似度计算调研"></a>短文本相似度计算调研</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>短文本相似度计算，即求解两个短文本之间的相似程度。目前，短文本相似度算法可以分为三大类：无监督相似度计算、有监督相似度计算，以及有监督+无监督的相似度计算。</p>
<h4 id="无监督相似度计算"><a href="#无监督相似度计算" class="headerlink" title="无监督相似度计算"></a>无监督相似度计算</h4><p>无监督相似度计算，又分为基于词汇重合度的TF-IDF（Term Frequency–Inverse Document Frequency）、BM25、Jaccard、VSM（Vector Space Model）、SimHash等模型，基于浅层语义的主题模型：LDA（Latent Dirichlet Allocation）、PLSA[1]（Probabilistic Latent Semantic Analysis）等，基于语义的编码模型：word to vector、WMD[2]（Word Mover’s Distance）、预训练编码器（如XLNet[3]、BERT[4]、ELMo[5]）等，以及基于以上各种方法的相似度分数的经验加权叠加。无监督方法的好处是不需要训练数据，可以直接通用于任何场景，缺点是准确度一般，常用于冷启动的场景。</p>
<h4 id="有监督相似度计算"><a href="#有监督相似度计算" class="headerlink" title="有监督相似度计算"></a>有监督相似度计算</h4><p>有监督的方法可以分为基于传统的分类模型，如LR（Logistic regression）、SVM、GBDT[6]（Gradient Boosting Decision Tree）等，以及基于深度神经网络的模型。基于深度神经网络的模型普遍分为两种思路：基于表示的模型与基于交互的模型。基于表示的模型主要基于孪生神经网络[7]（Siamese）结构，“孪生”是通过共享参数而实现的，将两个文本映射到同一空间，再计算相似度，例如DSSM（Deep Structured Semantic Models）、CLSM[8]（Convolutional Latent Semantic Model）、ARC-I[9]（Architecture-I）等等；优点是结构简单，可以用于构建索引等场景，缺点是两个短文本的编码完全独立进行，无法考虑任何短文本内部之间的关联。基于交互的模型为了解决上述问题，将编码的过程加入了短文本内部之间的关联参数矩阵，更好地把握了语义焦点，能对上下文重要性进行更好的建模，例如ARC-II[9]（Architecture-II）、MatchPyramid[10]、MVLSTM[11]（Multi-variable Long Short-Term Memory）等。有监督方法可以在特定的场景下通过有标签数据来定制化相似度模型，从而提高准确率；但是有标签数据的获取成本太大，学习的时间复杂度也很高。</p>
<h4 id="有监督-无监督的相似度计算"><a href="#有监督-无监督的相似度计算" class="headerlink" title="有监督+无监督的相似度计算"></a>有监督+无监督的相似度计算</h4><p>有监督和无监督的混合方法鉴于无监督学习和有监督学习的优缺点，将它们结合到一起，提高了无监督学习的准确率并且降低了有监督学习的时间成本。这种混合方法其实是一种迁移学习（迁移学习是一种机器学习的方法，指的是一个预训练的模型被重新用在另一个任务中，一般两种任务之间需要有一定的相似性和关联性），随着近年来研究的进行，其效果越来越突显出来，例如2018年google提出来的Bert模型[4]以及2019年google再次提出来的XLNet模型[3]，都在各项自然语言处理任务（包括短文本相似度）上取得了颠覆性的突破。其中，Bert借用了Transformer结构中的encoding部分来对文本进行编码，其基于Self-Attention机制，并引入了Positional Encoding，既能够有效地捕捉文本字符间的位置关系，又能并行计算以提高计算效率，只需要在大量的无监督数据集上进行模型的预训练，并在特定任务集合上做少量的fine-tune，便可以达到一个很不错的效果。当然，Bert的预训练过程也并不是完美无缺的，Bert的预训练语言模型目标函数的计算过程强行做了独立性假设，并且基于随机概率MASK的预训练文本和基于具体任务的整句文本fine-tune的过程，具有明显的不一致性。综上考虑，XLNet被提出，为了解决双向上下文的问题，XLNet引入了排列（permutation）语言模型。排列语言模型在预测时，需要预测目标的位置信息，因此将传统的Self-Attention修改为Two-Stream Self-Attention来捕捉位置信息；XLNet还借鉴了Transformer-XL的优点，它对于很长的上下文的处理是要优于传统的Transformer的。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1].  Hofmann T. Probabilistic latent semantic analysis[J]. arXiv preprint arXiv:1301.6705, 2013.</p>
<p>[2].  Kusner M, Sun Y, Kolkin N, et al. From word embeddings to document distances[C]. International conference on machine learning. 2015: 957-966.</p>
<p>[3].  Yang Z, Dai Z, Yang Y, et al. Xlnet: Generalized autoregressive pretraining for language understanding[C]. Advances in neural information processing systems. 2019: 5753-5763.</p>
<p>[4].  Devlin J, Chang M W, Lee K, et al. Bert: Pre-training of deep bidirectional transformers for language understanding[J]. arXiv preprint arXiv:1810.04805, 2018.</p>
<p>[5].  Peters M E, Neumann M, Iyyer M, et al. Deep contextualized word representations[J]. arXiv preprint arXiv:1802.05365, 2018.</p>
<p>[6].  Ke G, Meng Q, Finley T, et al. Lightgbm: A highly efficient gradient boosting decision tree[C]. Advances in neural information processing systems. 2017: 3146-3154.</p>
<p>[7].  Chopra S, Hadsell R, LeCun Y. Learning a similarity metric discriminatively, with application to face verification[C]. 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05). IEEE, 2005, 1: 539-546.</p>
<p>[8].  Shen Y, He X, Gao J, et al. A latent semantic model with convolutional-pooling structure for information retrieval[C]. Proceedings of the 23rd ACM international conference on conference on information and knowledge management. 2014: 101-110.</p>
<p>[9].  Hu B, Lu Z, Li H, et al. Convolutional neural network architectures for matching natural language sentences[C]. Advances in neural information processing systems. 2014: 2042-2050.</p>
<p>[10].       Pang L, Lan Y, Guo J, et al. Text matching as image recognition[J]. arXiv preprint arXiv:1602.06359, 2016.</p>
<p>[11].       Wan S, Lan Y, Guo J, et al. A deep architecture for semantic matching with multiple positional sentence representations[J]. arXiv preprint arXiv:1511.08277, 2015.</p>
]]></content>
      <tags>
        <tag>调研报告</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows下Github+Hexo搭建个人网站</title>
    <url>/2020/11/22/Windows%E4%B8%8BGithub-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/</url>
    <content><![CDATA[<p>Hexo是一款简约的静态博客框架，无广告、依赖少、易于安装使用、方便管理维护，可以生成静态网页并将其托管到Github上，对中文的支持也非常友好。我整理了自己的搭建过程，做了个简单的教程~</p>
<a id="more"></a>

<h2 id="Windows下Github-Hexo搭建个人网站"><a href="#Windows下Github-Hexo搭建个人网站" class="headerlink" title="Windows下Github + Hexo搭建个人网站"></a>Windows下Github + Hexo搭建个人网站</h2><h4 id="搭建步骤"><a href="#搭建步骤" class="headerlink" title="搭建步骤"></a>搭建步骤</h4><ol>
<li>安装Git</li>
<li>安装Node.js</li>
<li>配置Github pages</li>
<li>安装Hexo</li>
<li>推送网站</li>
<li>Hexo使用</li>
</ol>
<hr>
<h4 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h4><ul>
<li><p>Git是开源的分布式版本控制系统，用于敏捷高效地处理项目。个人网站在本地搭建好了，需要使用Git同步到GitHub上。附上<a href="https://git-scm.com/download/win">Git的官网下载地址</a>。Git的安装教程网上有很多，可自行查阅，不过多说明。</p>
</li>
<li><p>安装成功后，在开始菜单里搜索Git Bash，设置user.name和user.email配置信息：</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git config --global user.name <span class="string">&quot;你的GitHub用户名&quot;</span></span><br><span class="line">git config --global user.email <span class="string">&quot;你的GitHub注册邮箱&quot;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>输入命令：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/.ssh</span><br></pre></td></tr></table></figure>

<p>如果显示<code>No such file or directory</code>，则表示此电脑第一次使用SSH key。</p>
<ul>
<li>下面说明如何生成ssh密钥文件，输入命令：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;你的GitHub注册邮箱&quot;</span><br></pre></td></tr></table></figure>

<p>直接三个回车即可，默认不需要设置密码。</p>
<ul>
<li>然后找到生成的.ssh的文件夹中的id_rsa.pub密钥，将内容全部复制，</li>
</ul>
<p><img src="/2020/11/22/Windows%E4%B8%8BGithub-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/p1.png" alt="image1"></p>
<p>打开<a href="https://github.com/settings/keys">Github_Settings_keys</a>页面，新建new SSH Key，</p>
<p><img src="/2020/11/22/Windows%E4%B8%8BGithub-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/p2.png" alt="image2"></p>
<p>Title为标题，任意填即可，将刚刚复制的id_rsa.pub内容粘贴到Key字段，最后点击Add SSH key。</p>
<ul>
<li>在Git Bash中检测GitHub公钥设置是否成功，输入：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh git@github.com</span><br></pre></td></tr></table></figure>

<p>出现Connection to github.com closed，说明成功。这里之所以设置GitHub密钥原因是，通过非对称加密的公钥与私钥来完成加密，公钥放置在GitHub上，私钥放置在自己的电脑里。GitHub要求每次推送代码都是合法用户，所以每次推送都需要输入账号密码验证推送用户是否是合法用户，为了省去每次输入密码的步骤，采用了ssh，当你推送的时候，git就会匹配你的私钥跟GitHub上面的公钥是否是配对的，若是匹配就认为你是合法用户，则允许推送。这样可以保证每次的推送都是正确合法的。</p>
<hr>
<h4 id="安装Node-js"><a href="#安装Node-js" class="headerlink" title="安装Node.js"></a>安装Node.js</h4><ul>
<li>Hexo基于Node.js，附上<a href="https://nodejs.org/en/download/">Node.js下载地址</a>，下载安装包（LTS版本即可），注意安装Node.js会包含环境变量及npm的安装，安装后，检测Node.js是否安装成功，在命令行中输入：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure>

<ul>
<li>检测npm是否安装成功，在命令行中输入:</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm -v</span><br></pre></td></tr></table></figure>

<p>到这儿，安装Hexo的环境已经全部搭建完成。</p>
<hr>
<h4 id="配置Github-pages"><a href="#配置Github-pages" class="headerlink" title="配置Github pages"></a>配置Github pages</h4><ul>
<li>登录Github，点击”New repository”，新建一个仓库。输入仓库名：你的Github名称.github.io，然后点击 Create repository 。</li>
</ul>
<p><img src="/2020/11/22/Windows%E4%B8%8BGithub-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/p7.png" alt="image3"></p>
<p>注意：一定要用自己的github的用户名，不然显示不出来。用户名尽量选择小写字母+数字的组合。由于我已经创建过主页了，因此会显示已经存在，正常应该是一个绿色的对号。</p>
<ul>
<li>然后就是启用 GitHub Pages。点击仓库右边的 Setting 菜单进入设置，下滑找到GitHub Pages，选择分支是master，然后点击 Choose a theme随意选择一个模版，点击 Select theme ，发布github默认生成的一个静态站点。</li>
</ul>
<p><img src="/2020/11/22/Windows%E4%B8%8BGithub-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/p8.png" alt="image4"></p>
<ul>
<li>最后，在Setting的左侧导航栏找到“Branches”，在Default branch中设置为master。</li>
</ul>
<p><img src="/2020/11/22/Windows%E4%B8%8BGithub-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/p9.png" alt="image5"></p>
<hr>
<h4 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h4><ul>
<li>Hexo就是我们的个人博客网站的框架， 这里需要自己在电脑常里创建一个文件夹，可以命名为blog，Hexo框架与以后你自己发布的网页都在这个文件夹中。创建好后，进入文件夹中，右键，点击“Git Bash Here”：</li>
</ul>
<p><img src="/2020/11/22/Windows%E4%B8%8BGithub-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/p3.png" alt="image6"></p>
<ul>
<li>使用npm命令安装Hexo，输入：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g hexo</span><br></pre></td></tr></table></figure>

<ul>
<li>安装完成后，初始化我们的博客，输入：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init hexo</span><br></pre></td></tr></table></figure>

<p>注意，这里的命令都是作用在刚刚创建的blog文件夹中。</p>
<ul>
<li>为了检测我们的网站雏形，进入到hexo目录，分别按顺序输入以下三条命令：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new test_my_site		<span class="comment"># 新建文章</span></span><br><span class="line">hexo g						<span class="comment"># 生成网页</span></span><br><span class="line">hexo s						<span class="comment"># 启动本地预览</span></span><br></pre></td></tr></table></figure>

<ul>
<li>完成后，打开浏览器输入地址：<a href="http://loalhost:4000/">localhost:4000</a>，可以看出我们写出第一篇博客：</li>
</ul>
<p><img src="/2020/11/22/Windows%E4%B8%8BGithub-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/p4.png" alt="image7"></p>
<p>恭喜！出现此页面说明安装成功，在Git Bash中按<code>Ctrl+C</code>退出预览。</p>
<hr>
<h4 id="推送网站"><a href="#推送网站" class="headerlink" title="推送网站"></a>推送网站</h4><ul>
<li>上面只是在本地预览，接下来要做的就是就是推送网站，也就是发布网站，让我们的网站可以被更多的人访问。接下来需要将我们的Hexo与GitHub关联起来，打开hexo文件夹下的_config.yml文件，如下图：</li>
</ul>
<p><img src="/2020/11/22/Windows%E4%B8%8BGithub-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/p5.png" alt="image8"></p>
<ul>
<li>翻到最后修改为：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line"><span class="built_in">type</span>: git</span><br><span class="line">repo: 这里填入你之前在GitHub上创建仓库的完整路径，记得加上 .git</span><br><span class="line">branch: master</span><br></pre></td></tr></table></figure>

<p>参考如下：</p>
<p><img src="/2020/11/22/Windows%E4%B8%8BGithub-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/p6.png" alt="image9"></p>
<p>注意：’:’后一定留有空格，不然后续会报错。</p>
<ul>
<li>完成配置后保存文件。其实这就是给<code>hexo d</code>这个命令做相应的配置，让hexo知道你要把blog部署在哪个位置，很显然，我们部署在我们GitHub的仓库里。最后安装Git部署插件，输入命令：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>

<ul>
<li>这时，我们分别输入三条命令：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean			<span class="comment"># 清除缓存</span></span><br><span class="line">hexo g				<span class="comment"># 生成网页</span></span><br><span class="line">hexo d				<span class="comment"># 部署</span></span><br></pre></td></tr></table></figure>

<p>其实，第三条的<code>hexo d</code>就是部署网站命令，d是deploy的缩写。</p>
<ul>
<li>完成后，打开浏览器，在地址栏输入你的放置个人网站的仓库路径，即<a href="https://xxxx.github.io,这里的xxxx就是你的github用户名./">https://xxxx.github.io，这里的xxxx就是你的GitHub用户名。</a></li>
<li>你就会发现你的博客已经上线了，可以在网络上被访问了。P.S. 如果访问不了，尝试换DNS域名解析服务器，我的设置如下：</li>
</ul>
<p><img src="/2020/11/22/Windows%E4%B8%8BGithub-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/p10.png" alt="image10"></p>
<p>至此就大功告成啦！</p>
]]></content>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>知识图谱调研</title>
    <url>/2020/11/22/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%B0%83%E7%A0%94/</url>
    <content><![CDATA[<p>最近由于项目需要接触到一些知识图谱领域的知识，为了方便日后进一步研究或应用，先进行了宏观上的调研，总结了本篇调研报告。</p>
<a id="more"></a>

<h2 id="知识图谱调研"><a href="#知识图谱调研" class="headerlink" title="知识图谱调研"></a>知识图谱调研</h2><h4 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h4><ol>
<li>知识图谱的定义</li>
<li>国内外研究现状</li>
<li>代表性的知识图谱库</li>
<li>知识图谱的架构</li>
<li>知识图谱的构建技术</li>
<li>知识图谱的存储</li>
</ol>
<hr>
<h4 id="知识图谱的定义"><a href="#知识图谱的定义" class="headerlink" title="知识图谱的定义"></a>知识图谱的定义</h4><ul>
<li><p>从学术的角度，知识图谱是结构化的语义知识库，用于以符号形式描述物理世界中的概念及其相互关系。其基本组成单位是“实体－关系－实体”三元组，以及实体及其相关属性－ 值对，实体间通过关系相互联结，构成网状的知识结构。</p>
</li>
<li><p>从实际应用的角度，可以简单地把知识图谱理解成多关系图（Multi-relational Graph），其一般包含多种类型的节点和多种类型的边。在知识图谱里，我们通常用”实体（Entity）“来表达图里的节点、用“关系（Relation）”来表达图里的“边”。实体指的是现实世界中的事物，比如人、地名、概念、公司等，关系则用来表达不同实体之间的某种联系，比如人-“居住在”-北京、张三和李四是“朋友”等等。</p>
</li>
<li><p>该定义有三方面的含义：</p>
<ol>
<li>知识图谱本身是一个具有属性的实体通过关系链接而形成的网状知识库。从图的概念来看，知识图谱是对物理世界的一种符号表达；</li>
<li>知识图谱的研究价值在于：它是构建在当前Web基础上的一层覆盖网络，知识图谱的目标是在当前网页之间建立概念的链接，从而将互联网上的知识进行整合，成为“知识”；</li>
<li>知识图谱的应用价值在于，它可以帮助人们准确的锁定自己想要检索的内容，而不必从海量网页中人工过滤。</li>
</ol>
</li>
</ul>
<hr>
<h4 id="国内外研究现状"><a href="#国内外研究现状" class="headerlink" title="国内外研究现状"></a>国内外研究现状</h4><p>目前，国内外学者对其的研究主要集中于知识图谱的关键技术：</p>
<ul>
<li>知识表示；</li>
<li>知识图谱构建；</li>
<li>知识图谱应用。</li>
</ul>
<ol>
<li>知识表示的发展过程主要分为三个阶段：</li>
</ol>
<ul>
<li>比较早时期采用符号逻辑的方式；</li>
<li>2000年以后出现的语义网对知识进行表示的方式，包括RDF、OWL等；</li>
<li>目前比较流行的采用表示学习方式，将知识学习成低维稠密的向量，通过向量间的关系可以在某种程度上反映知识之间的关系。</li>
</ul>
<ol start="2">
<li><p>知识图谱的构建主要是三个步骤：</p>
<ul>
<li><p>知识抽取</p>
<ul>
<li>知识抽取的目标就是从数据源中抽取出实体、关系及属性等信息，进而进行下一步的操作，所以这一项工作更准确地说应该叫做信息抽取，因为这一步骤并不能得到我们最终想要的“知识”；</li>
<li>这一步骤涉及到的主要技术包括：实体抽取、关系抽取以及属性抽取。</li>
</ul>
</li>
<li><p>知识融合</p>
<ul>
<li>知识融合过程中，需要对第一步中抽取出的三元组信息进行处理，比如将指向同一类实体的三元组进行合并，或者将同名不同含义的实体进行区分；</li>
<li>这一步骤涉及的技术是指代消解、实体消歧和知识合并。</li>
</ul>
</li>
<li><p>知识加工</p>
<ul>
<li>知识加工是将前两步骤处理后的数据转换为结构化的知识；</li>
<li>主要包括三方面内容：本体构建，知识推理和质量评估。</li>
</ul>
</li>
</ul>
</li>
<li><p>知识图谱的应用主要有三个方向：</p>
<ul>
<li>语义搜索，利用知识图谱所具有的良好定义的结构形式，以有向图的方式提供满足用户需求的结构化语义内容；</li>
<li>知识问答，基于知识库的问答，通过对问句的语义分析，转换成结构化的查询语句，在已有结构化的知识库上获取答案；</li>
<li>知识驱动的大数据分析与决策。</li>
</ul>
</li>
<li><p>根据覆盖范围而言，知识图谱也可分为：</p>
<ul>
<li>开放域通用知识图谱<ul>
<li>开放通用知识图谱注重广度，强调融合更多的实体，较垂直行业知识图谱而言，其准确度不够高，并且受概念范围的影响，很难借助本体库对公理、规则以及约束条件的支持能力规范其实体、属性、实体间的关系等。</li>
</ul>
</li>
<li>垂直行业知识图谱<ul>
<li>行业知识图谱通常需要依靠特定行业的数据来构建，具有特定的行业意义。行业知识图谱中，实体的属性与数据模式往往比较丰富，需要考虑到不同的业务场景与使用人员。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h4 id="代表性的知识图谱库"><a href="#代表性的知识图谱库" class="headerlink" title="代表性的知识图谱库"></a>代表性的知识图谱库</h4><p><img src="/2020/11/22/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%B0%83%E7%A0%94/p1.png" alt="代表性知识图谱库"></p>
<hr>
<h4 id="知识图谱的架构"><a href="#知识图谱的架构" class="headerlink" title="知识图谱的架构"></a>知识图谱的架构</h4><ul>
<li><p>逻辑架构</p>
<ul>
<li><p>所谓逻辑架构，指的是图谱的双层结构：数据层和模式层。</p>
</li>
<li><p>在数据层，知识以事实（fact）为单位存储在图数据库中。事实一般以三元组的方式进行描述，例如“实体-关系-实体”、“实体-属性-属性值”，借此，图数据库中所有的数据将组成庞大的关系网络，形成所谓的“图谱”。</p>
</li>
<li><p>模式层建立在数据层之上，按照字面意思理解就是：对数据层的知识设置一种过滤模式，从而减少知识的冗余。举个例子，比如一个人可能有两个名字，在数据层，不同的名字可能对应了不同的属性和关系，而模式层就是把这实质上是同一个人的实体及其关系进行融合（知识融合），去除不必要的冗余。</p>
</li>
</ul>
<p><img src="/2020/11/22/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%B0%83%E7%A0%94/p2.png" alt="逻辑架构"></p>
</li>
<li><p>技术架构</p>
<p>知识图谱的整体技术流程如下图所示：</p>
<p><img src="/2020/11/22/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%B0%83%E7%A0%94/p3.png" alt="知识图谱技术流程图"></p>
<p>橘色部分代表着知识图谱的构建及迭代过程：知识抽取、知识融合、知识加工。一般人们会把知识图谱的构建分为自顶而下和自底而上两种不同的形式，随着技术的不断成熟，现在大都采用自底而上的方法，即从数据中提取资源模式，通过一定的技术手段，选择其中置信度较高的部分，加入到知识图谱中去。</p>
</li>
</ul>
<hr>
<h4 id="知识图谱的构建技术"><a href="#知识图谱的构建技术" class="headerlink" title="知识图谱的构建技术"></a>知识图谱的构建技术</h4><p>上文提到，知识图谱的构建及迭代主要是三个步骤，下面就每个步骤进行说明。</p>
<ol>
<li><p>知识抽取（Knowledge Extraction）</p>
<p>知识抽取的目标就是从数据源中抽取出实体、关系及属性等信息，进而进行下一步的操作，所以这一项工作更准确地说应该叫做信息抽取，因为这一步骤并不能得到我们最终想要的“知识”。相应地，这一步骤涉及到的主要技术包括：实体抽取、关系抽取以及属性抽取。</p>
<ul>
<li><p>实体抽取</p>
<p>即所谓的命名实体识别（Named Entity Recognition，NER），指的就是如何从数据，特别是文本数据中准确获得其中的实体信息。实体的类型主要包括三大类七小类：</p>
<ul>
<li>实体类（包括人名，地名，机构名）；</li>
<li>时间类（日期，时间）</li>
<li>数字类（货币、百分比）</li>
</ul>
<p>具体到特定领域，还可以对实体类别进行扩充。</p>
</li>
<li><p>关系抽取</p>
<p>实体抽取获得了图数据库中的节点，那么关系抽取就是获得节点之间的连线的过程。<br>在早期的研究中，关系抽取同样基于规则，但这种方法本身的局限注定基于规则建立模型不是长久之计；后来采用统计机器学习的方法，得到了不错的效果，但需要大量人工标注的语料，这对于特定领域的关系抽取来说，工作量无疑是巨大的；再后来的基于半监督、无监督以及自监督模型，对模型的通用性有了一些提高，但整体来说，由于自然语言的复杂性，这一领域的学者仍然是任重而道远。</p>
</li>
<li><p>属性抽取</p>
<p>如果把实体的属性值看作是一种特殊的实体，那么属性抽取实际上也是一种关系抽取。 百科类网站提供的半结构化数据是通用领域属性抽取研究的主要数据来源，但具体到特定的应用领域，涉及大量的非结构化数据，属性抽取仍然是一个巨大的挑战。</p>
</li>
</ul>
</li>
<li><p>知识融合（Knowledge Fusion）</p>
<p>上一步抽取出的三元组信息存入数据库后，具备了初步的“知识”，但这些知识仍然不能直接利用。例如，对于前美国总统奥巴马，我们可能用不同的词来称呼他，在实体识别中这些称呼都被看作是独立的实体，那么我们就应该把这些指向同一类实体的三元组进行合并。再举一个例子，同名同姓的两个不同的人，如何区分他们呢？这就涉及下面的技术。</p>
<ul>
<li><p>指代消解</p>
<p>这个词可能不是很好理解，但理解它所代表的意思即可：消解那些指代不同实体的内容，这一技术就是处理对同一实体的不同语言描述问题（如上文对奥巴马的不同称呼）。利用这一技术，就可以将这些看似不同的实体归纳到一个统一的实体。这一技术本身也具有很多“称呼”：实体对齐，实体匹配，实体同义等。</p>
</li>
<li><p>实体消歧</p>
<p>相比而言，这个词就好理解多了，其作用也简单，就是对具有相同名称的实体进行区分。例如两个人同名，那就通过性别、工作、兴趣爱好等其他属性进行区分。</p>
</li>
<li><p>知识合并</p>
<p>知识合并主要就是从结构化数据或者第三方库中获取知识并融合进图谱的过程。</p>
</li>
</ul>
</li>
<li><p>知识加工（Knowledge Processing）</p>
<p>严格来讲，经过前两步骤处理后的数据仍不能称得上是“知识”，只能算是事实表达的集合，要想获得结构化的知识，还需要经过知识加工环节。知识加工主要包括3方面内容： 本体构建，知识推理和质量评估。</p>
<ul>
<li><p>本体构建</p>
<p>本体最早是一个哲学上的概念，在知识图谱上引用本体构建这一技术，目的是对相关领域的知识进行总结提取，确定在该领域内得到共识的术语，然后以格式规范的定义来描述这些内容。可以这样理解，前两阶段提取出来的实体及其属性关系，是本体的具体表现；而本体就是对它们的概括总结。</p>
</li>
<li><p>知识推理</p>
<p>知识推理指的是从已有的知识中推理出新的知识。例如康熙是雍正的父亲，雍正是乾隆的父亲，那么通过康熙和乾隆这两个实体之间通过知识推理，就可以获得他们之间是祖孙关系。</p>
</li>
<li><p>质量评估</p>
<p>顾名思义，质量评估就是对写入知识图谱中的知识做最后的判断，以提高知识库中内容的准确性。</p>
</li>
</ul>
</li>
<li><p>知识更新（Knowledge Update）</p>
<p>知识图谱并不是一成不变的，随着人类知识的增加，图谱的内容也要定期进行更新，以满足最新的知识需求。更新的方式有两种，一种是“打补丁”，即增量更新，将新增加的人类知识经过处理加入到知识图谱中；另一种是“推倒重建”，即全局更新，就是从零开始重建新图谱。事实上，无论哪种方法都是一件消耗巨大的工作。</p>
</li>
</ol>
<hr>
<h4 id="知识图谱的存储"><a href="#知识图谱的存储" class="headerlink" title="知识图谱的存储"></a>知识图谱的存储</h4><p>知识图谱主要有两种存储方式：一种是基于RDF的存储；另一种是基于图数据库的存储。它们之间的区别如下图所示。RDF一个重要的设计原则是数据的易发布、共享，图数据库则把重点放在了高效的图查询和搜索上；此外，RDF以三元组的方式来存储数据而且不包含属性信息，但图数据库一般以属性图为基本的表示形式，所以实体和关系可以包含属性，这就意味着更容易表达现实的业务场景。</p>
<p><img src="/2020/11/22/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%B0%83%E7%A0%94/p4.png" alt="区别"></p>
<p>根据最新的统计，图数据库仍然是增长最快的存储系统。相反，关系型数据库的增长基本保持在一个稳定的水平。下图列出了常用的图数据库系统以及他们最新使用情况的排名。 其中Neo4j系统目前仍是使用率最高的图数据库，它拥有活跃的社区，而且系统本身的查询效率高，但唯一的不足就是不支持准分布式；相反，OrientDB和JanusGraph（原Titan）支持分布式，但这些系统相对较新，社区不如Neo4j活跃，这也就意味着使用过程当中不可避免地会遇到一些刺手的问题。如果选择RDF的存储系统，Jena或许一个比较不错的选择。</p>
<p><img src="/2020/11/22/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%B0%83%E7%A0%94/p5.png" alt="数据库"></p>
]]></content>
      <tags>
        <tag>调研报告</tag>
      </tags>
  </entry>
  <entry>
    <title>西瓜书第三章思维导图</title>
    <url>/2020/11/22/%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/</url>
    <content><![CDATA[<p>日常学习周志华教授的西瓜书，读完第三章：线性模型，绘制了思维导图，方便日后复习。</p>
<a id="more"></a>

<h1 id="线性模型思维导图"><a href="#线性模型思维导图" class="headerlink" title="线性模型思维导图"></a>线性模型思维导图</h1><p><img src="/2020/11/22/%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.png" alt="西瓜书第三章思维导图"></p>
<hr>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="基本形式"><a href="#基本形式" class="headerlink" title="基本形式"></a>基本形式</h3><ul>
<li>线性模型试图学得一个通过属性的线性组合来进行预测的函数</li>
</ul>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul>
<li>形式简单、易于建模</li>
<li>许多非线性模型可在线性模型的基础上通过引入层级结构或高维映射而得</li>
<li>线性模型中各个属性前的系数w直观地表达了各属性在预测中的重要性，因此线性模型有很好的可解释性</li>
</ul>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="试图学得一个线性模型以尽可能准确地预测实值输出标记"><a href="#试图学得一个线性模型以尽可能准确地预测实值输出标记" class="headerlink" title="试图学得一个线性模型以尽可能准确地预测实值输出标记"></a>试图学得一个线性模型以尽可能准确地预测实值输出标记</h3><ul>
<li><p>若属性只有一个</p>
<ul>
<li><p>存在“序”关系</p>
<ul>
<li><p>二值属性</p>
<ul>
<li>用0/1表示两个属性值</li>
</ul>
</li>
<li><p>三值属性</p>
<ul>
<li>用0/0.5/1表示三个属性值</li>
</ul>
</li>
</ul>
</li>
<li><p>无“序”关系</p>
<ul>
<li><p>多个属性值用类似“独热向量”的方式表示，如(0,0,1)/(0,1,0)/(1,0,0)。</p>
<ul>
<li><p>注意</p>
<ul>
<li>如果将无序属性连续化，则会不恰当地引入序关系，对后续处理如距离计算等造成误差。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>如何衡量预测值与真实值之间的差别？</p>
<ul>
<li><p>均方误差</p>
<ul>
<li><p>均方误差的几何意义对应了欧几里得距离（欧氏距离）</p>
</li>
<li><p>基于均方误差最小化的模型求解方法是“最小二乘法”。在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧式距离之和最小。</p>
<ul>
<li>寻找欧氏距离最小化的过程称为线性回归模型的最小二乘“参数估计”。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>若属性有多个</p>
<ul>
<li><p>多元线性回归</p>
<ul>
<li>使均方误差最小化的解不唯一，选择哪个解，将由学习算法的归纳偏好决定，常见的做法是引入正则化项。</li>
</ul>
</li>
</ul>
</li>
<li><p>特别地</p>
<ul>
<li><p>对数线性回归</p>
<ul>
<li>令模型预测值逼近y的对数，反应了所对应的输出标记在指数尺度上的变化。</li>
<li>形式上仍是线性回归，但实质上已是在求取输入空间到输出空间的非线性函数映射。</li>
</ul>
</li>
<li><p>广义线性模型</p>
<ul>
<li><p>将上述的对数函数换成任意单调可微函数（连续且充分），其中，这个函数称为“联系函数”。对数线性回归是广义线性模型在联系函数为对数函数时的特例。</p>
<ul>
<li><p>参数估计方法</p>
<ul>
<li>加权最小二乘法或极大似然法</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="对数几率回归"><a href="#对数几率回归" class="headerlink" title="对数几率回归"></a>对数几率回归</h2><h3 id="解决分类任务"><a href="#解决分类任务" class="headerlink" title="解决分类任务"></a>解决分类任务</h3><ul>
<li><p>二分类任务</p>
<ul>
<li><p>需要将线性回归模型产生的预测值（实值）转换为0/1</p>
<ul>
<li><p>单位阶跃函数</p>
<ul>
<li>若预测值大于0就判为正例</li>
<li>若预测值小于零就判为反例</li>
<li>若预测值为临界值零则可任意判别</li>
</ul>
</li>
<li><p>对数几率函数</p>
<ul>
<li><p>是一种Sigmoid函数</p>
<ul>
<li>将预测值转化为一个接近0或1的y值，并且其输出值在0附近变化地很陡。</li>
</ul>
</li>
<li><p>实际上是在用线性回归模型的预测结果去逼近真实标记的对数几率</p>
<ul>
<li><p>注意</p>
<ul>
<li>也有文献称为“逻辑回归”</li>
<li>虽然名字是“回归”，但却是一种分类学习方法</li>
</ul>
</li>
</ul>
</li>
<li><p>优点</p>
<ul>
<li>直接对分类的可能性进行建模，无需事先假设数据分布，避免了假设分布不准确所带来的问题</li>
<li>不仅预测出“类别”，而且可得到近似概率预测，这对许多需利用概率辅助决策的任务很有用</li>
<li>对数几率函数（简称对率函数）是任意阶可导的凸函数，有很好的数学性质，现有的许多数值优化算法都可直接用于求取最优解。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="线性判别分析"><a href="#线性判别分析" class="headerlink" title="线性判别分析"></a>线性判别分析</h2><h3 id="给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能地接近、异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。"><a href="#给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能地接近、异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。" class="headerlink" title="给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能地接近、异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。"></a>给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能地接近、异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。</h3><ul>
<li><p>LDA（线性判别分析）的欲最大化目标是广义瑞利商</p>
<ul>
<li>二分类</li>
<li>可推广至多分类</li>
</ul>
</li>
</ul>
<h2 id="多分类学习"><a href="#多分类学习" class="headerlink" title="多分类学习"></a>多分类学习</h2><h3 id="有些二分类学习方法可推广至多分类"><a href="#有些二分类学习方法可推广至多分类" class="headerlink" title="有些二分类学习方法可推广至多分类"></a>有些二分类学习方法可推广至多分类</h3><ul>
<li>比如LDA的推广</li>
</ul>
<h3 id="更一般地，基于一些基本策略，利用二分类学习器来解决多分类问题"><a href="#更一般地，基于一些基本策略，利用二分类学习器来解决多分类问题" class="headerlink" title="更一般地，基于一些基本策略，利用二分类学习器来解决多分类问题"></a>更一般地，基于一些基本策略，利用二分类学习器来解决多分类问题</h3><ul>
<li><p>基本思路</p>
<ul>
<li><p>“拆解法”，即将多分类任务拆为若干个二分类任务求解。</p>
<ul>
<li><p>具体来说，先对问题进行拆分，然后为拆出的每个二分类任务训练一个分类器；在测试时，对这些分类器的预测结果进行集成以获得最终的多分类结果。</p>
<ul>
<li><p>关键问题</p>
<ul>
<li>如何对多分类任务进行拆分？</li>
<li>如何对多个分类器进行集成？</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="拆分策略"><a href="#拆分策略" class="headerlink" title="拆分策略"></a>拆分策略</h3><ul>
<li><p>一对一（OvO）</p>
<ul>
<li>将N个类别两两配对，从而产生N(N-1)/2个二分类任务；在测试阶段，新样本将同时提交给所有分类器，于是我们将得到N(N-1)/2个分类结果，最终结果可通过投票（或各分类器的预测置信度等信息）产生。</li>
</ul>
</li>
<li><p>一对其余（OvR）</p>
<ul>
<li>每次将一个类的样例作为正例、所有其他类的样例作为反例来训练N个分类器。在测试时若只有一个分类器预测为正类，则对应的类别标记作为最终分类结果；否则，通常考虑各分类器的预测置信度，选择置信度最大的类别标记作为分类结果。</li>
</ul>
</li>
<li><p>多对多（MvM）</p>
<ul>
<li><p>每次将若干个类作为正类，若干个其他类作为反类。</p>
<ul>
<li>一对一和一对其余均是多对多的特例</li>
</ul>
</li>
<li><p>MvM的正、反类构造必须有特殊的设计，不能随意选取。</p>
<ul>
<li><p>纠错输出码（ECOC）</p>
<ul>
<li><p>最常用的MvM技术。ECOC是将编码的思想引入类别拆分，并尽可能在解码过程中具有容错性。</p>
<ul>
<li><p>步骤一：编码：对N个类别做M次划分，每次划分将一部分类别划为正类，一部分划为反类，从而形成一个二分类训练集；这样一共产生M个训练集，可训练出M个分类器。</p>
<ul>
<li><p>类别划分通过“编码矩阵”指定。编码矩阵有多种形式，常见的主要有二元码、三元码。</p>
<ul>
<li>二元码：将每个类别分别指定为正类和反类。</li>
<li>三元码：在正、反类之外，还可指定“停用类”（不使用该类样本）。</li>
</ul>
</li>
</ul>
</li>
<li><p>步骤二：解码：M个分类器分别对测试样本进行预测，这些预测标记组成一个编码。将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="类别不平衡问题"><a href="#类别不平衡问题" class="headerlink" title="类别不平衡问题"></a>类别不平衡问题</h2><h3 id="当分类任务中不同类别的训练样例数目不平衡且差别较大时，如何进行学习？"><a href="#当分类任务中不同类别的训练样例数目不平衡且差别较大时，如何进行学习？" class="headerlink" title="当分类任务中不同类别的训练样例数目不平衡且差别较大时，如何进行学习？"></a>当分类任务中不同类别的训练样例数目不平衡且差别较大时，如何进行学习？</h3><ul>
<li><p>基本策略：再缩放（再平衡）rescaling</p>
<ul>
<li><p>y’/1-y’ = (y/1-y) * (m-/m+)</p>
<ul>
<li><p>再缩放的思想简单，但实际操作并不平凡，主要因为“训练集是真实样本总体的无偏采样”这个假设往往并不成立，也就是说，我们未必能有效地基于训练集观测几率来推断出真实几率。</p>
<ul>
<li><p>现有技术大体上有三类做法</p>
<ul>
<li>对训练集里的反类样例（这里假设反类样例远多于正类样例）进行“欠采样”（亦称“下采样”），即去除一些反例使得正、反例数目接近，然后再进行学习。</li>
<li>对训练集里的正类样例（这里假设反类样例远多于正类样例）进行“过采样”（亦称“上采样”），即增加一些正例使得正、反例数目接近，然后再进行学习。</li>
<li>基于原始训练集进行学习，但在用训练好的分类器进行预测时，将前面的式子嵌入到其决策过程中，称为“阈值移动”。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>值得一提，“再缩放”也是“代价敏感学习”的基础。</p>
</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>西瓜书笔记</tag>
      </tags>
  </entry>
</search>
